# -*- coding: utf-8 -*-
"""Experiment7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eo2frVnADmCR6bX3Xs0TsL9AwdeCGy_Z
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import time

import matplotlib.pyplot as plt
import numpy as np

epochs = 20

"""# Load data and transform"""

transform = transforms.Compose(
    [transforms.RandomRotation(30),
     transforms.RandomHorizontalFlip(),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR100(root='./data', train= True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR100(root='./data', train= False,
                                        download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size = 4,
                                          shuffle=True, num_workers=2)

classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
          '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',
          '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',
          '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',
          '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',
          '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',
          '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',
          '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',
          '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',
          '90', '91', '92', '93', '94', '95', '96', '97', '98', '99')

"""# SqueezeNet for 32x32 CIFAR"""

import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
class Fire(nn.Module):

    def __init__(self, inplanes, squeeze_planes,
                 expand1x1_planes, expand3x3_planes):
        super(Fire, self).__init__()
        self.inplanes = inplanes
        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)
        self.squeeze_activation = nn.ReLU(inplace=True)
        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,
                                   kernel_size=1)
        self.expand1x1_activation = nn.ReLU(inplace=True)
        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,
                                   kernel_size=3, padding=1)
        self.expand3x3_activation = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.squeeze_activation(self.squeeze(x))
        return torch.cat([
            self.expand1x1_activation(self.expand1x1(x)),
            self.expand3x3_activation(self.expand3x3(x))
        ], 1)


class SqueezeNet(nn.Module):

    def __init__(self, version=1.0, num_classes=100):
        super(SqueezeNet, self).__init__()
        self.num_classes = num_classes

        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=2, stride=1, padding=1),
            nn.ReLU(inplace=True),
#             nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),
            Fire(96, 16, 64, 64),
            Fire(128, 16, 64, 64),
            Fire(128, 32, 128, 128),
            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),
            Fire(256, 32, 128, 128),
            Fire(256, 48, 192, 192),
            Fire(384, 48, 192, 192),
            Fire(384, 64, 256, 256),
            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),
            Fire(512, 64, 256, 256),
            )

        # Final convolution is initialized differently from the rest
        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            final_conv,
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1))
        )

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                if m is final_conv:
                    init.normal_(m.weight, mean=0.0, std=0.01)
                else:
                    init.kaiming_uniform_(m.weight)
                if m.bias is not None:
                    init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x.view(x.size(0), self.num_classes)

def squeezenet():
    net = SqueezeNet()
    return net

"""## Load previous model"""

net  = squeezenet()

import torch.optim as optim

criterion = nn.CrossEntropyLoss().cuda()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

"""# Train the network"""

# Detect GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# move model to device
net.to(device)

steps = 0

# Model training and validation
loss_list_training = []
accuracy_list_training = []
# loss_list_validation = []
accuracy_list_validation = []


since = time.time()
for epoch in range(epochs):
    correct = 0
    total = 0
    running_loss = 0

    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        # Move input and label tensors to the default device

        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)

        # Get predicted classes and number of correctly classified instances
        y_pred = torch.max(outputs.data, 1)[1]
        correct += float((y_pred == labels).sum())
        total += float(len(labels))


        loss.backward()
        optimizer.step()

        # Store loss value on training
        loss_list_training.append(loss.item())

        #print statistics
        running_loss += loss.item()

        if i % 2000 == 1999: #print every 2000 mini-batches
            print ('[%d, %5d] avg loss: %.3f accuracy so far: %.3f' %
                   (epoch + 1, i + 1, running_loss / 2000,100*correct/total ))
            running_loss = 0

    # Store loss value on training
    # loss_list_training.append(loss.item())

    # Calculate accuracy and store on training
    accuracy_training = 100*correct/total
    accuracy_list_training.append(accuracy_training)
    
    correctV = 0
    totalV = 0
    with torch.no_grad():
      for dataV in testloader:
          imagesV, labelsV = dataV
          imagesV, labelsV = imagesV.to(device), labelsV.to(device)
          outputsV = net(imagesV)
          _, predictedV = torch.max(outputsV.data.cuda(), 1)
          totalV += labelsV.size(0)
          correctV += (predictedV == labelsV).sum().item()
    accuracy_validation = 100*correctV/totalV
    accuracy_list_validation.append(accuracy_validation)


    print(f"Epoch : {epoch+1}     "
          f"Total Time : {time.time() - since}         "
          f"Training Accuracy : {accuracy_training}         "
          f"Validation Accuracy : {accuracy_validation}     "
          f"Training Loss : {loss.item()}     ")
          # f"Validation Loss : {loss_validation.data.item()} ")
      
    # TEMP: loss and accuracy plots
    f = plt.figure(2)
    plt.plot(range(1,len(accuracy_list_training)+1), accuracy_list_training)
    plt.plot(range(1,len(accuracy_list_validation)+1), accuracy_list_validation)
    plt.title('Accuracy vs number of epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend(('Training','Validation'), loc='upper left')
    f.show()
    f.savefig('Accuracy.jpg')
    plt.close(f)

    f = plt.figure(3)
    plt.plot(range(1,len(loss_list_training)+1), loss_list_training)
    # plt.plot(range(len(loss_list_validation)), loss_list_validation)
    plt.title('Training Loss vs number of epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(('Training loss'), loc='upper left')
    f.show()
    f.savefig('Loss.jpg')
    plt.close(f)

accuracy_list_validation

#show statistics
time_elapsed = time.time() - since
print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))

# TEMP: loss and accuracy plots
f = plt.figure(2)
plt.plot(range(1,len(accuracy_list_training)+1), accuracy_list_training)
plt.plot(range(1,len(accuracy_list_validation)+1), accuracy_list_validation)
plt.title('Accuracy vs number of epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(('Training','Validation'), loc='upper left')
f.show()

f = plt.figure(3)
plt.plot(range(1,len(loss_list_training)+1), loss_list_training)
# plt.plot(range(len(loss_list_validation)), loss_list_validation)
plt.title('Training Loss vs number of epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(('Training accuracy'), loc='upper left')
f.show()

############################################################
# Test the network on the test data

correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data.cuda(), 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))

# what are the classes that performed well, and the classes that did
# not perform well:
class_correct = list(0. for i in range(100))
class_total = list(0. for i in range(100))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1
for i in range(100):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))

#Save the model
#name of the model: (number of epochs_kernel size_stride_padding_(kernel size_stride)x3)
path = str(epochs) + '_2_1_2_2_2' + "(acc=" + str(100 * correct / total) + ")cifar100"
torch.save(net.state_dict(), path)
model = squeezenet()
model.load_state_dict(torch.load(path))
model.eval()

model.to(device)
from torchsummary import summary
summary(model,input_size=(3,32,32))

